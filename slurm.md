# SLURM Configuration of Virtual box cluster

## Setup
Install munge that is used by slurm as authentication service, on all nodes. If you are using a Virtual box cluster, install it on one virtual machine and then clone it.
```bash
sudo apt-get install munge slurm-wlm
```

Remember to copy file ```/etc/munge/munge.key``` from master to all other nodes, in order to share it across all nodes.

## Configuration file

This is a little bit akward, it is the main source of errors if it is not well formed.

I used this one for my cluster of master+node01, file should be created in ```/etc/slurm-llnl/slurm.conf```.
In the slurm installation dir, an automatic configurator html page is created but I suggest to use a custom file since I had difficulties to install the scheduler with the automatic version.

```conf
# slurm.conf file generated by configurator easy.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ControlMachine=master
#ControlAddr=192.168.30.246
#
#MailProg=/bin/mail
MpiDefault=none
#MpiParams=ports=#-#
ProctrackType=proctrack/pgid
ReturnToService=1
SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid
#SlurmctldPort=6817
SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid
#SlurmdPort=6818
SlurmdSpoolDir=/var/lib/slurm-llnl/slurmd

SlurmUser=slurm
#SlurmdUser=root
StateSaveLocation=/var/lib/slurm-llnl/slurmctld
SwitchType=switch/none
TaskPlugin=task/none
#
#
# TIMERS
#KillWait=30
#MinJobAge=300
#SlurmctldTimeout=120
#SlurmdTimeout=300
#
#
# SCHEDULING
FastSchedule=1
SchedulerType=sched/backfill
#SchedulerPort=7321
#SelectType=select/linear
SelectType=select/cons_res
SelectTypeParameters=CR_CPU
#
#
# LOGGING AND ACCOUNTING
AccountingStorageType=accounting_storage/none
ClusterName=cluster
#JobAcctGatherFrequency=30
JobAcctGatherType=jobacct_gather/none
#SlurmctldDebug=3
SlurmctldLogFile=/var/log/slurm-llnl/slurmctld.log
#SlurmdDebug=3
SlurmdLogFile=/var/log/slurm-llnl/slurmd.log
#
#
# COMPUTE NODES
NodeName=master NodeAddr=192.168.100.100 NodeHostname=master CPUs=2 State=UNKNOWN
NodeName=node01 NodeAddr=192.168.100.101 CPUs=2 State=IDLE

# PARTITIONS
PartitionName=debug Default=YES MaxTime=INFINITE State=UP Nodes=master,node01
```
This is a stable version of my slurm.conf file.

On the master you must do these lines to enable slurm controller service.
```bash
sudo systemctl enable slurmctld
sudo systemctl start slurmctld
```
The slurm daemons must be started in all nodes.
```bash
sudo systemctl enable slurmd
sudo systemctl start slurmd
```

## Cluster checking

Check if the partitions have been detected:
```bash
sinfo

PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
debug*       up   infinite      2   idle master,node01
```

If nodes and nodelist are the same as in your configuration file, it is ok!!

Then check the status of your nodes
```bash
scontrol show node

NodeName=master Arch=x86_64 CoresPerSocket=2
   CPUAlloc=0 CPUErr=0 CPUTot=2 CPULoad=0.70
   AvailableFeatures=(null)
   ActiveFeatures=(null)
   Gres=(null)
   NodeAddr=192.168.100.100 NodeHostName=master Version=17.11
   OS=Linux 4.15.0-45-generic #48-Ubuntu SMP Tue Jan 29 16:28:13 UTC 2019 
   RealMemory=1 AllocMem=0 FreeMem=82 Sockets=1 Boards=1
   State=IDLE ThreadsPerCore=1 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A
   Partitions=debug 
   BootTime=2019-01-31T15:24:07 SlurmdStartTime=2019-02-01T15:07:31
   CfgTRES=cpu=2,mem=1M,billing=2
   AllocTRES=
   CapWatts=n/a
   CurrentWatts=0 LowestJoules=0 ConsumedJoules=0
   ExtSensorsJoules=n/s ExtSensorsWatts=0 ExtSensorsTemp=n/s
   

NodeName=node01 Arch=x86_64 CoresPerSocket=2
   CPUAlloc=0 CPUErr=0 CPUTot=2 CPULoad=0.20
   AvailableFeatures=(null)
   ActiveFeatures=(null)
   Gres=(null)
   NodeAddr=192.168.100.101 NodeHostName=node01 Version=17.11
   OS=Linux 4.15.0-45-generic #48-Ubuntu SMP Tue Jan 29 16:28:13 UTC 2019 
   RealMemory=1 AllocMem=0 FreeMem=323 Sockets=1 Boards=1
   State=IDLE ThreadsPerCore=1 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A
   Partitions=debug 
   BootTime=2019-01-31T15:26:40 SlurmdStartTime=2019-02-01T15:07:53
   CfgTRES=cpu=2,mem=1M,billing=2
   AllocTRES=
   CapWatts=n/a
   CurrentWatts=0 LowestJoules=0 ConsumedJoules=0
   ExtSensorsJoules=n/s ExtSensorsWatts=0 ExtSensorsTemp=n/s
```

Sometimes it may happen that node status is ```State=DOWN+DRAIN```
This is showed also when typing ```sinfo```

```bash
sinfo 
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
debug*       up   infinite      1  drain node01
debug*       up   infinite      1   idle master
```

To wake up the node you need to type on your master:
```bash
sudo scontrol update NodeName=node01 State=IDLE
```

Then ```sinfo``` should look like:
```bash
sinfo
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
debug*       up   infinite      2   idle master,node01
```

Now you can start a task in your node to see if computation is distributed.

```bash
srun -N2 hostname
node01
master
```

Now your slurm scheduler is ok!! 

# Useful commands

We showed some useful commands as ```sinfo``` and ```scontrol show node```.

Using ```squeue``` you can see the list of jobs launched on the cluster.
```bash
squeue

             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
                73     debug dask-wor   robbis  R       5:23      1 master
                74     debug dask-wor   robbis  R       5:23      1 master
                75     debug dask-wor   robbis  R       5:20      1 node01
                76     debug dask-wor   robbis  R       5:20      1 node01
```

Using ```scancel``` you can kill these jobs as well, where argument is the PID of the job.

```bash
scancel 73
```




